{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eae760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #For jum002 HPC setup\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(\"/home/jum002/store5/repo/smrt\")\n",
    "# sys.path.append(\"/home/jum002/store5/repo/snowmicropyn\")\n",
    "# os.chdir(\"/home/jum002/code-workshop/AKROSS_paper/Code-paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8e14e-85f5-468f-b57a-4091d26e6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "# Need forked snowmicropyn from https://github.com/mjsandells/snowmicropyn\n",
    "from snowmicropyn import density_ssa, profile, loewe2012\n",
    "import akross_common_functions as AK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# King 2020 coefficients for rho. SSA coef (montpetit et al 2023)\n",
    "# those SSA coef require np.exp(ssa) later\n",
    "k2020_coeffs = {'density':[312.54, 50.27, -50.26, -85.35], 'ssa':[2.37, -0.7, -0.06], 'equation':'ssa'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3716b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier from https://github.com/kingjml/SMP-Sea-Ice/tree/master\n",
    "layer_class = pd.read_pickle('smrt_in-out/svm_layer_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435bd6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_profile(profile, classifier):\n",
    "    #thuis is used to classify smp profile with grain type label. Then we assume a polydispersity for these label\n",
    "    temp_profile = profile.copy()\n",
    "    \n",
    "    profile_prediction = classifier.predict(temp_profile)\n",
    "    profile_prediction[profile_prediction=='R'] = 1\n",
    "    profile_prediction[profile_prediction=='F'] = 2\n",
    "    profile_prediction[profile_prediction=='H'] = 3\n",
    "    \n",
    "    temp_profile['layer_type'] = profile_prediction.astype(int)\n",
    "    \n",
    "    #Layers must be at least 1 cm\n",
    "    temp_profile['layer_type'] =  temp_profile['layer_type'].rolling(window=3, min_periods=1).apply(lambda x: mode(x)[0]).values.astype(int)\n",
    "    temp_profile['layer_label'] =  temp_profile['layer_type']\n",
    "    \n",
    "    temp_profile.loc[temp_profile['layer_type'] == 1, 'layer_label'] = 'R'\n",
    "    temp_profile.loc[temp_profile['layer_type'] == 2, 'layer_label'] = 'F'\n",
    "    temp_profile.loc[temp_profile['layer_type'] == 3, 'layer_label'] = 'H'\n",
    "\n",
    "    return temp_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f36d94a",
   "metadata": {},
   "source": [
    "### Alert and Eureka\n",
    "Prepare smp dataframe with Salinity and temperature from pit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smp_snowpacks(list_of_filenames, list_of_file_sites, salt_dict, temp_dict, layer_thickness=0.03):\n",
    "    # Function to take in an SMP measurement file, derive density and SSA\n",
    "    # And generate SMRT snowpack\n",
    "    # layer_thickness governs the thickness of layers to be used in SMRT\n",
    "    # default layer_thickness is 5cm    \n",
    "        \n",
    "    snowpacks = []\n",
    "    \n",
    "    # Loop over SMP files for site:\n",
    "    for smp, site in zip(list_of_filenames, list_of_file_sites):\n",
    "        \n",
    "        # 1. Take median and process density / SSA\n",
    "        #smp_median = density_ssa.median_profile([smp])\n",
    "        try:\n",
    "            smp_profile = profile.Profile(smp)\n",
    "            surface = smp_profile.detect_surface()\n",
    "            ground = smp_profile.detect_ground()\n",
    "            df_param = density_ssa.calc(smp_profile.samples_within_snowpack(), coeff_model=k2020_coeffs, window=5, overlap=50)\n",
    "            \n",
    "            #grain type classifier\n",
    "            sn = loewe2012.calc(smp_profile.samples_within_snowpack(), window=5)\n",
    "            svm_df = pd.DataFrame(data={'relative_height': sn.distance, 'l': sn.L2012_L, 'force_median': sn.force_median})\n",
    "            profile_prediction = classify_profile(svm_df, layer_class)\n",
    "            #get poly\n",
    "            #poly values = 0.7 for all grain execpt 1.3 for hoar\n",
    "            poly = [0.7 if (label == 'R' or label == 'F') else 1.3  for label in profile_prediction.layer_label]\n",
    "            df_param['polydispersity'] = poly\n",
    "            \n",
    "            total_depth_in_m = df_param.distance.iloc[-1] * 1e-3\n",
    "\n",
    "            # 2. Group density / SSA into layers. Take median\n",
    "            current_thickness = df_param.distance.diff().iloc[-1] * 1e-3 # Convert to m\n",
    "            number_in_group = int(layer_thickness / current_thickness)\n",
    "            df = df_param.rolling(number_in_group).median()\n",
    "            df = df.iloc[number_in_group::number_in_group, :]\n",
    "\n",
    "            # 3. Calculate number of layers needed\n",
    "            nlayers = len(df)\n",
    "\n",
    "            # 4. Assign layer thickness from top, with any remaining depth allocated to bottom layer\n",
    "            thickness_array = nlayers * [layer_thickness]\n",
    "            # Add in remaining profile to lowest layer\n",
    "            extra_thickness = total_depth_in_m - sum(thickness_array)\n",
    "            thickness_array[-1] += extra_thickness\n",
    "            df['thick'] = thickness_array\n",
    "            \n",
    "            # 5. Extract density\n",
    "            df['density'] = df.density\n",
    "\n",
    "            # 6. Derive exp corr length\n",
    "            df['ssa'] = np.exp(df.ssa)\n",
    "\n",
    "            #get height from salt and temp interpolation\n",
    "            height = np.cumsum(thickness_array[::-1])\n",
    "\n",
    "            # #get poly\n",
    "            # #poly values = 0.7 for all grain execpt 1.3 for hoar\n",
    "            # poly = [0.7 if (label == 'R' or label == 'F') else 1.3  for label in c2020_m.layer_label]\n",
    "            # df['polydispersity'] = poly\n",
    "\n",
    "            #set salinity of snow layer\n",
    "            salt_pit = salt_dict[site]\n",
    "            df['salinity'] = np.interp(height, salt_pit.height[::-1].values/100, salt_pit.param[::-1])[::-1]\n",
    "\n",
    "            #settemp array\n",
    "            temp_pit = temp_dict[site]\n",
    "            temp_pit.param[temp_pit.param <-22] = -22\n",
    "            df['temperature'] = np.interp(height, temp_pit.height[::-1].values/100, temp_pit.param[::-1])[::-1] + 273\n",
    "\n",
    "            snowpacks.append(df)\n",
    "\n",
    "        except:\n",
    "            print ('make snowpack failed for', smp)\n",
    "            pass\n",
    "            \n",
    "    return snowpacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f06a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_dict = pd.read_pickle('smrt_in-out/alert_eureka_salt_dict')\n",
    "temp_dict = pd.read_pickle('smrt_in-out/alert_eureka_temp_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of sites (upper folders)\n",
    "# Data from https://doi.org/10.5281/zenodo.4068349\n",
    "\n",
    "#data_dir = '../DATA/SMP/Sites'\n",
    "#data_dir = 'C:/Users/melochej/Documents/code-workshop/AKROSS/DATA/SMP/Sites'\n",
    "data_dir = '/home/jum002/store5/data/AKROSS_data/Alert-Eureka/SMP/Sites'\n",
    "\n",
    "list_of_sites = os.listdir(path=data_dir)\n",
    "# Split Eureka and Alert sites\n",
    "eureka_sites = [s for s in list_of_sites if 'Eureka' in s]\n",
    "alert_sites = [s for s in list_of_sites if 'Alert' in s]\n",
    "\n",
    "E_smp_files, E_smp_sites = [], []\n",
    "for s in eureka_sites:\n",
    "    E_smp_files.append(AK.find_site_smp_files(s, data_dir = data_dir)[0])\n",
    "    E_smp_sites.append(AK.find_site_smp_files(s, data_dir = data_dir)[1])\n",
    "# Flatten list of lists\n",
    "eureka_smp_files = list(itertools.chain(*E_smp_files))\n",
    "eureka_smp_sites = list(itertools.chain(*E_smp_sites))\n",
    "\n",
    "\n",
    "A_smp_files, A_smp_sites = [], []\n",
    "for s in alert_sites:\n",
    "    A_smp_files.append(AK.find_site_smp_files(s, data_dir = data_dir)[0])\n",
    "    A_smp_sites.append(AK.find_site_smp_files(s, data_dir = data_dir)[1])\n",
    "# Flatten list of lists\n",
    "alert_smp_files = list(itertools.chain(*A_smp_files))\n",
    "alert_smp_sites = list(itertools.chain(*A_smp_sites))\n",
    "\n",
    "\n",
    "list_smp_E16 = smp_snowpacks(eureka_smp_files, eureka_smp_sites, salt_dict, temp_dict, layer_thickness=0.03)\n",
    "list_smp_A = smp_snowpacks(alert_smp_files, alert_smp_sites, salt_dict, temp_dict, layer_thickness=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb10ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('smrt_in-out/smp_profile_E16_3cm', 'wb') as pickle_file:\n",
    "    pickle.dump(list_smp_E16, pickle_file)\n",
    "\n",
    "with open('smrt_in-out/smp_profile_A_3cm', 'wb') as pickle_file:\n",
    "    pickle.dump(list_smp_A, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450927cf",
   "metadata": {},
   "source": [
    "### Cambay\n",
    "Prepare smp dataframe with Salinity and temperature from pit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e6b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/jum002/store5/data/AKROSS_data/CB22/SMP/Sites/'\n",
    "\n",
    "def build_smp_input(site, layer_thickness, snow_info):\n",
    "    list_smp = sorted(os.listdir(data_dir + site))\n",
    "    list_profile = []\n",
    "\n",
    "    #import snow pit info fro temp and salinity\n",
    "    temperature_pit = snow_info[site].temperature\n",
    "    salinity_pit = snow_info[site].salinity\n",
    "    htop_pit = snow_info[site].htop #convert to m\n",
    "    for smp in list_smp: \n",
    "        if smp.lower().endswith(\".pnt\"):\n",
    "            try:\n",
    "                smp_profile = profile.Profile(data_dir + site +'/'+ smp)\n",
    "                surface = smp_profile.detect_surface()\n",
    "                ground = smp_profile.detect_ground()\n",
    "                df_param = density_ssa.calc(smp_profile.samples_within_snowpack(), coeff_model=k2020_coeffs, window=5, overlap=50)\n",
    "\n",
    "                #grain type classifier\n",
    "                sn = loewe2012.calc(smp_profile.samples_within_snowpack(), window=5)\n",
    "                svm_df = pd.DataFrame(data={'relative_height': sn.distance, 'l': sn.L2012_L, 'force_median': sn.force_median})\n",
    "                profile_prediction = classify_profile(svm_df, layer_class)\n",
    "                #get poly\n",
    "                #poly values = 0.7 for all grain execpt 1.3 for hoar\n",
    "                poly = [0.7 if (label == 'R' or label == 'F') else 1.3  for label in profile_prediction.layer_label]\n",
    "                df_param['polydispersity'] = poly\n",
    "                \n",
    "                #get rolling median for define thickness for smrt\n",
    "                current_thickness = df_param.distance.diff().iloc[-1] * 1e-3 # Convert to m\n",
    "                number_in_group = int(layer_thickness / current_thickness)\n",
    "                df_final = df_param.rolling(number_in_group).median()\n",
    "                smp_smrt = df_final.iloc[number_in_group::number_in_group, :]\n",
    "                smp_smrt['ssa'] = np.exp(smp_smrt.ssa)\n",
    "                #get temperature and salinity from pit info\n",
    "                htop_smp = (smp_smrt.distance.values[-1] - smp_smrt.distance) * 1e-3  \n",
    "                thick = [layer_thickness for i in range(0,len(htop_smp))]\n",
    "                # indice [::-1] because x needs to be monotonically increasing\n",
    "                temperature = np.interp(htop_smp[::-1], htop_pit[::-1], temperature_pit)\n",
    "                salinity = np.interp(htop_smp[::-1], htop_pit[::-1].iloc[:-1], salinity_pit.iloc[:-1])\n",
    "                salinity[-1] = salinity_pit.iloc[-1]\n",
    "\n",
    "\n",
    "                #add to dataframe\n",
    "                smp_smrt.loc[:,'temperature'] = temperature\n",
    "                smp_smrt.loc[:,'salinity'] = salinity\n",
    "                smp_smrt.loc[:,'thick'] = thick\n",
    "                #smp_smrt.loc[:,'polydispersity'] = polydispersity\n",
    "\n",
    "                list_profile.append(smp_smrt)\n",
    "            except Exception as error:\n",
    "                #print(error)\n",
    "                print(f'error with {smp}, less than layer thickness define...')\n",
    "\n",
    "\n",
    "    return list_profile\n",
    "\n",
    "\n",
    "import pickle\n",
    "#import snowpit info from pickle file\n",
    "with open('smrt_in-out/snowpitCB2022_SMRT_input.txt', 'rb') as pickle_file:\n",
    "    snow_info = pickle.load(pickle_file)\n",
    "\n",
    "#3cm\n",
    "ds_AK1 = build_smp_input('AK1', 0.03, snow_info)\n",
    "ds_AK2 = build_smp_input('AK2', 0.03, snow_info)\n",
    "ds_AK3 = build_smp_input('AK3', 0.03, snow_info)\n",
    "ds_AK4 = build_smp_input('AK4', 0.03, snow_info)\n",
    "\n",
    "list_smp_CB = ds_AK1 + ds_AK2 + ds_AK3 + ds_AK4\n",
    "\n",
    "with open('smrt_in-out/smp_profile_CB_3cm', 'wb') as pickle_file:\n",
    "    pickle.dump(list_smp_CB, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65205e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds_AK1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2874e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other layer thickness to check with CT\n",
    "\n",
    "#5mm\n",
    "ds_AK1 = build_smp_input('AK1', 0.005, snow_info)\n",
    "ds_AK2 = build_smp_input('AK2', 0.005, snow_info)\n",
    "ds_AK3 = build_smp_input('AK3', 0.005, snow_info)\n",
    "ds_AK4 = build_smp_input('AK4', 0.005, snow_info)\n",
    "\n",
    "list_smp_CB = ds_AK1 + ds_AK2 + ds_AK3 + ds_AK4\n",
    "\n",
    "with open('smrt_in-out/smp_profile_CB_5mm', 'wb') as pickle_file:\n",
    "    pickle.dump(list_smp_CB, pickle_file)\n",
    "\n",
    "#1cm\n",
    "ds_AK1 = build_smp_input('AK1', 0.01, snow_info)\n",
    "ds_AK2 = build_smp_input('AK2', 0.01, snow_info)\n",
    "ds_AK3 = build_smp_input('AK3', 0.01, snow_info)\n",
    "ds_AK4 = build_smp_input('AK4', 0.01, snow_info)\n",
    "\n",
    "list_smp_CB = ds_AK1 + ds_AK2 + ds_AK3 + ds_AK4\n",
    "\n",
    "with open('smrt_in-out/smp_profile_CB_1cm', 'wb') as pickle_file:\n",
    "    pickle.dump(list_smp_CB, pickle_file)\n",
    "\n",
    "#2cm\n",
    "ds_AK1 = build_smp_input('AK1', 0.02, snow_info)\n",
    "ds_AK2 = build_smp_input('AK2', 0.02, snow_info)\n",
    "ds_AK3 = build_smp_input('AK3', 0.02, snow_info)\n",
    "ds_AK4 = build_smp_input('AK4', 0.02, snow_info)\n",
    "\n",
    "list_smp_CB = ds_AK1 + ds_AK2 + ds_AK3 + ds_AK4\n",
    "\n",
    "with open('smrt_in-out/smp_profile_CB_2cm', 'wb') as pickle_file:\n",
    "    pickle.dump(list_smp_CB, pickle_file)\n",
    "\n",
    "#5cm\n",
    "ds_AK1 = build_smp_input('AK1', 0.05, snow_info)\n",
    "ds_AK2 = build_smp_input('AK2', 0.05, snow_info)\n",
    "ds_AK3 = build_smp_input('AK3', 0.05, snow_info)\n",
    "ds_AK4 = build_smp_input('AK4', 0.05, snow_info)\n",
    "\n",
    "list_smp_CB = ds_AK1 + ds_AK2 + ds_AK3 + ds_AK4\n",
    "\n",
    "with open('smrt_in-out/smp_profile_CB_5cm', 'wb') as pickle_file:\n",
    "    pickle.dump(list_smp_CB, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bedf8",
   "metadata": {},
   "source": [
    "#### Eureka 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67752e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pit_folder = \"/home/jum002/store5/data/AKROSS_data/Eureka22/PIT/Daily_pit_files\"\n",
    "smp_daily = \"/home/jum002/store5/data/AKROSS_data/Eureka22/SMP/2022-04_AllDailySMPNotes_Combined.xlsx\"\n",
    "dir_smp = \"/home/jum002/store5/data/AKROSS_data/Eureka22/SMP/RAW_pnt_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ac22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#build dictionnary of temperature from pit\n",
    "dict_site = {}\n",
    "for file in os.listdir(data_pit_folder):\n",
    "    df = pd.read_excel(os.path.join(data_pit_folder, file), sheet_name = \"PIT\", skiprows = 7)\n",
    "    df_salt = pd.read_excel(os.path.join(data_pit_folder, file), sheet_name = \"Salinity\")\n",
    "\n",
    "    site = file[11:-21]\n",
    "    temperature = df['Temp.'][1:].dropna().values\n",
    "    height = df['Height above ground'][1:].dropna().values\n",
    "    salinity = df_salt['PPT'].dropna().values\n",
    "    height_salinity = df_salt['Height'].dropna().values\n",
    "\n",
    "    #temperature limit Ã  -22 for saline snow\n",
    "    # index = np.where(temperature <=-22)\n",
    "    # temperature[index] = -22\n",
    "            \n",
    "\n",
    "    dict_temp = {'height' : height, 'temperature' : temperature + 273, 'height_salt' : height_salinity, 'salinity' : salinity}\n",
    "    dict_site[site] = dict_temp\n",
    "\n",
    "#get refrence for smp file to corresponding pit\n",
    "df_smp_note = pd.read_excel(smp_daily)\n",
    "dict_smp = {}\n",
    "for index, row in df_smp_note.iterrows():\n",
    "    dict_smp[str(row['File'])] = row['Site Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd705cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_smp_name = sorted(os.listdir(dir_smp))\n",
    "\n",
    "layer_thickness = 0.03\n",
    "\n",
    "list_smp_E22, list_smp_nopit = [], []\n",
    "for smp in list_smp_name:\n",
    "    ssa, density, depth = [], [], []\n",
    "    if smp.lower().endswith(\".pnt\"):\n",
    "        smp_profile = profile.Profile(os.path.join(dir_smp, smp))\n",
    "        surface = smp_profile.detect_surface()\n",
    "        ground = smp_profile.detect_ground()\n",
    "        df = smp_profile.samples_within_snowpack()\n",
    "        df_param = density_ssa.calc(df, coeff_model=k2020_coeffs, window=5, overlap=50)\n",
    "\n",
    "        #grain type classifier\n",
    "        sn = loewe2012.calc(smp_profile.samples_within_snowpack(), window=5)\n",
    "        svm_df = pd.DataFrame(data={'relative_height': sn.distance, 'l': sn.L2012_L, 'force_median': sn.force_median})\n",
    "        profile_prediction = classify_profile(svm_df, layer_class)\n",
    "        #get poly\n",
    "        #poly values = 0.7 for all grain execpt 1.3 for hoar\n",
    "        poly = [0.7 if (label == 'R' or label == 'F') else 1.3  for label in profile_prediction.layer_label]\n",
    "        df_param['polydispersity'] = poly\n",
    "                \n",
    "        #total depth\n",
    "        total_depth_in_m = df_param.distance.iloc[-1] * 1e-3\n",
    "\n",
    "        #get rolling median for define thickness for smrt\n",
    "        current_thickness = df_param.distance.diff().iloc[-1] * 1e-3 # Convert to m\n",
    "        number_in_group = int(layer_thickness / current_thickness)\n",
    "        df_final = df_param.rolling(number_in_group).median()\n",
    "        smp_smrt = df_final.iloc[number_in_group::number_in_group, :]\n",
    "\n",
    "\n",
    "        try:\n",
    "            #get temperature from pit\n",
    "            site_temp = dict_smp[smp[4:-4]]\n",
    "            temperature_pit = np.array(dict_site[site_temp]['temperature'], dtype = float)\n",
    "            htop_pit = np.array(dict_site[site_temp]['height'], dtype = float) * 1e-2\n",
    "            salinity_pit = np.array(dict_site[site_temp]['salinity'], dtype = float)[:-1]\n",
    "            htop_salt = np.array(dict_site[site_temp]['height_salt'], dtype = float)[:-1]* 1e-2\n",
    "\n",
    "            #get temperature and salinity from pit info\n",
    "            depth = smp_smrt.distance.values * 1e-3\n",
    "            #4. Assign layer thickness from top, with any remaining depth allocated to bottom layer\n",
    "            thick = [layer_thickness for i in range(0,len(depth))]\n",
    "            # Add in remaining profile to lowest layer\n",
    "            extra_thickness = total_depth_in_m - sum(thick)\n",
    "            thick[-1] += extra_thickness\n",
    "\n",
    "            htop_smp = np.cumsum(np.array(thick)[::-1])[::-1]\n",
    "\n",
    "            # indice [::-1] because x needs to be monotonically increasing\n",
    "            temperature = np.interp(htop_smp[::-1], htop_pit[::-1], temperature_pit[::-1])[::-1]\n",
    "            salinity = np.interp(htop_smp[::-1], htop_salt[::-1], salinity_pit[::-1])[::-1]\n",
    "\n",
    "            list_smp_E22.append(pd.DataFrame({'ssa' : np.exp(smp_smrt.ssa.values), 'density' : smp_smrt.density.values, 'htop' : htop_smp,\n",
    "                                                'thick' : thick, 'temperature' : temperature, 'salinity' : salinity, \n",
    "                                                'pit' : site_temp, 'polydispersity' : smp_smrt.polydispersity.values}))\n",
    "        except:\n",
    "            print(f'no pit found for file : {smp}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('smrt_in-out/smp_profile_E22_3cm', 'wb') as pickle_file:\n",
    "    pickle.dump(list_smp_E22, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a4279",
   "metadata": {},
   "source": [
    "###  Box plot of snow properties for each site\n",
    "fig in methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_param(list_smp):\n",
    "    site_ssa = [item for sublist in [list(pit.ssa.values) for pit in list_smp] for item in sublist]\n",
    "    site_density = [item for sublist in [list(pit.density.values) for pit in list_smp] for item in sublist]\n",
    "    site_depth = np.array([np.sum(pit.thick) for pit in list_smp]) * 1e3\n",
    "\n",
    "    return site_ssa, site_density, site_depth\n",
    "\n",
    "E22_ssa, E22_density, E22_depth = get_all_param(list_smp_E22)\n",
    "CB_ssa, CB_density, CB_depth = get_all_param(list_smp_CB)\n",
    "A_ssa, A_density, A_depth = get_all_param(list_smp_A)\n",
    "E16_ssa, E16_density, E16_depth = get_all_param(list_smp_E16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = ['Alert-17', 'Eureka-16', 'Eureka-22', 'CB-22']\n",
    "\n",
    "# Make box plots\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.close()\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(5,6))\n",
    "ax1.boxplot([A_depth, E16_depth, E22_depth, CB_depth], showfliers=False)\n",
    "ax2.boxplot([A_density, E16_density, E22_density, CB_density], showfliers=False)\n",
    "ax3.boxplot([A_ssa, E16_ssa, E22_ssa, CB_ssa], showfliers=False)\n",
    "\n",
    "ax1.set_ylabel('Depth [mm]')\n",
    "ax2.set_ylabel('Density [kg m$^{-3}$]')\n",
    "ax3.set_ylabel('SSA [m$^2$ kg$^{-1}$]')\n",
    "\n",
    "ax1.set_yticks([0,200,400,600])\n",
    "ax2.set_yticks([200,300,400,500])\n",
    "ax3.set_yticks([0,20,40,60])\n",
    "\n",
    "ax3.set_xticklabels([])\n",
    "ax3.set_xticks(range(1,5))\n",
    "ax3.set_xticklabels(sites, rotation=0);\n",
    "\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "ax3.grid()\n",
    "\n",
    "\n",
    "#jul_path = 'C:/Users/melochej/OneDrive - EC-EC/Documents/post-doc/AKROSS/article/fig_output'\n",
    "#plt.savefig(jul_path +'SMP_data.png', format='png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMDS310",
   "language": "python",
   "name": "cmds310"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
